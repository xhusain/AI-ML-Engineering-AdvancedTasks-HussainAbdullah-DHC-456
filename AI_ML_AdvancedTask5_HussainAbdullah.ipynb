{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhxgFSC6Hxhu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "#dataset link: https://www.kaggle.com/datasets/adisongoh/it-service-ticket-classification-dataset\n",
        "csv_path = r\"D:\\AU\\Internships\\DHC - ML\\AI_ML_AdvancedTasks\\AI-ML-AdvancedTask5_HussainAbdullah\\all_tickets_processed_improved_v3.csv\"\n",
        "\n",
        "# ---------- 1. Load Dataset ----------\n",
        "df = pd.read_csv(csv_path)\n",
        "df = df.rename(columns={\"Subject\": \"subject\", \"Body\": \"body\", \"Types\": \"label\"})\n",
        "df[\"text\"] = df[\"subject\"].astype(str) + \" \" + df[\"body\"].astype(str)\n",
        "labels = sorted(df[\"label\"].unique())\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "df[\"labels\"] = df[\"label\"].map(label2id)\n",
        "\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# ---------- 2. Zero-Shot Prompting ----------\n",
        "def zero_shot_tags(text, top_k=3):\n",
        "    prompt = f\"\"\"Classify this support ticket into {top_k} most relevant tags from: {labels}.\n",
        "Ticket:\n",
        "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
        "Respond as a JSON: {{ \"tags\": [\"tag1\", \"tag2\", \"tag3\"] }}\"\"\"\n",
        "    resp = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return resp.choices[0].message[\"content\"]\n",
        "\n",
        "# ---------- 3. Few-Shot Prompting ----------\n",
        "few_examples = [\n",
        "    {\"text\": \"My app crashes when I open settings\", \"tags\": [\"Technical Support\", \"Bug\", \"High Priority\"]},\n",
        "    {\"text\": \"Please send my invoice for March\", \"tags\": [\"Billing\", \"Customer Service\", \"Low Priority\"]},\n",
        "]\n",
        "\n",
        "def few_shot_tags(text, examples=few_examples, top_k=3):\n",
        "    ex_str = \"\\n\".join(f\"Ticket: \\\"{e['text']}\\\"\\nTags: {e['tags']}\" for e in examples)\n",
        "    prompt = ex_str + f\"\\n\\nNow classify:\\nTicket: \\\"{text}\\\"\\nTags:\"\n",
        "    resp = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return resp.choices[0].message[\"content\"]\n",
        "\n",
        "# ---------- 4. Fine-Tune a Transformer ----------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def preprocess(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tokenized_ds = dataset.map(preprocess, batched=True)\n",
        "tokenized_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, y_true = eval_pred\n",
        "    y_pred = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    }\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,  \n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_ds,\n",
        "    eval_dataset=tokenized_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "finetuned_clf = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, top_k=3)\n",
        "\n",
        "def finetuned_tags(text):\n",
        "    preds = finetuned_clf(text)\n",
        "    return [f\"{p['label']} ({round(p['score'],2)})\" for p in preds[0]]\n",
        "\n",
        "# ---------- 5. Gradio App ----------\n",
        "def classify_ticket(text):\n",
        "    z = zero_shot_tags(text)\n",
        "    f = few_shot_tags(text)\n",
        "    ft = finetuned_tags(text)\n",
        "    return z, f, ft\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=classify_ticket,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\"text\", \"text\", \"text\"],\n",
        "    title=\"Support Ticket Auto-Tagger\",\n",
        "    description=\"Zero-shot, few-shot, and fine-tuned classification\"\n",
        ")\n",
        "iface.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
